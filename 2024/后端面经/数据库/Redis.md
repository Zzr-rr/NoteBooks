## Redis为什么适合计数的场景

Redis处理命令是单线程的，所以执行命令的过程是原子的。因此String数据类型适合计数场景。



## Redis如何实现分布式锁

Redis分布式锁的实现主要依赖于指令`SETNX`，执行该指令有两种情况。

- 如果key不存在，则插入。
- 如果key存在，则返回0。

通过这样的操作来进行加锁，一般来说，分布式锁会加上过期时间，以防止锁失效。

```redis
SET lock_key unique_value NX PX 10000
```

**解锁**的过程就是删除lock_key，但是不能乱删。要保证执行操作的客户端就是有锁的客户端，即判断客户端的unique_value是否与`GET lock_key`返回的值相同。

那么解锁的过程就可以被分为两个操作，一是判断客户端是否持有锁，二是删除锁。因此就需要保证原子性，而Redis执行Lua脚本的时候，可以以**原子性**的方式进行，保证了锁释放操作的**原子性**。



## 为什么Lua脚本能够保证原子性

> Blocking semantics that ensure the script's atomic execution.

当执行脚本时，所有的服务器活动在脚本的执行期间都会被阻塞。



## 如何实现消息队列？消息队列需要保证什么特性？

消息队列的特性是：1、保序性，首先得保证消息的顺序是能够得到保障的。2、可靠性，要保证消息不会丢失。3、去重性，要保证消息不会被重复处理。

**保序性**可以用队列这样的数据结构来实现，一端进，一端出。如果是List，使用LPUSH来存取消息，通过RPOP来读取消息，这样处理有一定的问题，就是消息处理者要时刻确保队列中没有消息，需要不停的RPOP，这样会使得**CPU空转**，对CPU有不必要的消耗。因此Redis为了解决这样一个问题，提供了BRPOP这样的命令，即阻塞式读取。

**可靠性**，即消息不能丢失，最简单想到的就是备份了，通过RPOPLPUSH来将消息push到另外一个队列中进行备份。

**去重性**，事件在保存的时候需要存入**唯一标识符**（或者叫全局ID）。

Redis5.0版本之后，为消息队列而生产了一个新的数据结构，Stream，比List优越性在于：

能够实现消费组，使得一条消息被多个消费者去消费。

**可靠性**的保障可以类比计算机网络中TCP三次挥手的思想，即消息被消费者消费后需要消费者向消息队列发送ACK信息，即确认信息。



### 追问：用Redis实现消息队列有没有可能丢失消息？

消息从产生到消费，依次会经过生产者，中间件以及消费者（消息队列存储在消费者）。

唯一有可能丢失消息的是中间件。

原因：AOF持久化配置为每秒写盘，写盘过程是**异步**的，在此过程中容易出现消息丢失的可能；主从复制也是**异步**的，**主从切换**时，也有丢失数据的可能。



## 什么是消费组

一条消息的消费对象可能不只一个消费者，那么多个消费者都可以组成一个消费组。List是不支持消费组的实现的，而Stream支持。



## HyperLogLog有什么作用？其底层是如何是实现的？

HyperLogLog是一种用于统计基数的数据结构，即统计集合中不重复的元素的个数，标准误算率是0.81%。每个HyperLogLog大概仅需要消耗12KB内存，就可以实现对$2^{64}$个不同元素的基数统计。

HyperLogLog的底层基于概率实现。





## Redis的两种持久化技术？他们的持久化是怎么做的？

AOF日志和RDB快照。

AOF日志其实就是记录的我们一系列的操作（读操作是被忽略的，因为读操作对于Redis数据库不会产生影响，因此其记录也并没有意义）。有了这个日志系统，那么Redis就能够根据执行的操作一步步复原出Redis本该有的样子。

RDB快照文件的内容都是二进制数据。结合Mysql中的快照去理解。可以直接读入内存，不像AOF一样需要执行指令，所以速度会快于AOF。



## 讲一讲AOF的三种写回策略

Redis通过配置文件中的`appendfsync`参数来配置写回策略，always，everysec和no，名字的意义很明确。这三种写回策略各有侧重。

- always：每次写操作之后都会将AOF日志数据写回磁盘。
- everysec：每次写操作之后先把写操作的日志加入到内核缓冲区中，每隔一秒钟由内核缓冲区统一写到磁盘
- No：不由Redis控制写回磁盘的时机，转而将控制权限交给操作系统决定。

这三种写回策略主要是在性能和数据丢失率之间的平衡。



## AOF的重写为什么通过子进程来实现而不是新的线程？

线程和线程之间是有**共享内存区**的，如果通过一个新的线程来完成对AOF的重写，需要对AOF的数据进行加锁，保证原来AOF的数据不被污染。

但是如果通过子进程的方式来重写的话，父子进程之间虽然也共享内存数据，但是这种共享是**只读**的，也就是说子进程不会对父进程的数据内的数据造成改动，避免了加锁的额外开销。



### 追问1：重写的过程是怎么样的？

先写一个新的，写完之后再覆盖原有的。



### 追问2：子进程如何拥有父进程的数据备份？

主进程通过fork系统调用生成`bgrewriteaof`子进程的时候，操作系统会把主进程的页表的复制一份给子进程，这个页表记录了虚拟地址和物理地址映射关系，**页表对应的页表项的属性会标记为只读**。



### 追问3：如果子进程硬要写，操作系统会怎么办？

这里涉及到一个技术，叫做写时复制，就是你要写了，那么操作系统就给你复制一份备份，并且修改该**页表项的权限**为可读写。



### 追问4：重写的操作是有一定时间的，在此期间主进程又修改了数据，那该怎么办？

主进程创建了子进程之后会启用一个**AOF重写缓冲区**，重写AOF期间，Redis执行一个写命令，就会同时向**AOF缓冲区**和**AOF重写缓冲区**都写入记录。当子进程完成重写的操作之后，会向主进程发送一个信号，告知主进程重写已完成，这时候主进程收到信号之后：会把AOF重写缓冲区中的所有内容加到新的AOF文件中；新的AOF的文件进行改名，完成覆盖操作。



### 追问5：重写的时候会不会阻塞主进程？如果会，什么时候会发生？

会阻塞，一般只有

1. 子进程发生写的时候，会发生写时复制（需要复制页表，主进程会阻塞）。
2. fork子进程的时候，需要复制页表，主进程阻塞。
3. 最后子进程通知完成之后（父进程要操作AOF重写缓冲区）。



## RDB快照有什么弊端？

如果说RDB快照文件创建完之后崩溃了，那么此时的RDB快照只是子进程fork之前的内容，在fork之后做出的修改是不会被保留的，数据丢失。

极端情况下，写时复制在写操作很频繁的情况下可能会占用两倍的内存（所有的内存占用是原先的两倍）。



### 追问1：如何解决上述问题？

Redis4.0之后提出了一种混合的方式，前半部分（fork之前）使用RDB，后半部分使用AOF（fork之后），将fork之后做出的修改通过AOF重写缓冲区的形式记录下来。

写入完成之后就是用RDB+AOF替换原来的AOF内容。



## 介绍一下Redis的键过期是如何实现的？

Redis的键过期主要是通过**过期删除策略**来实现的。

主要是通过**过期字典**这样的数据结构去做，过期字典的key和value分别是一个指针，指向某个键和一个long long类型的整数，保存了key的过期时间。

三种删除策略：定时删除（通过定时事件）、惰性删除（懒删除）、定期删除。





## 介绍一下Redis的内存淘汰策略

内存淘汰策略，主要是两种，一种是不进行数据淘汰，还有一种是进行数据淘汰。

首先是不进行数据淘汰，就是直接禁止外部数据再次加入即可。

进行数据淘汰就涉及到淘汰的策略，主要是在两个范围内进行操作，一个是在已经过期的数据中操作，还有一种是在未过期的数据中操作。

在已经过期的数据中操作和未在过期中的数据操作仅仅是有一种淘汰方式不一样，就是TTL方式，即根据过期时间的长短来进行淘汰。

其它三种淘汰方式分别是random，lru，lfu。

综上组合起来共有3 * 2 + 1(ttl) + 1(不进行数据淘汰)，共计8种。



### 追问1：Redis的LRU算法是如何实现的？

基于链表的LRU算法会有额外的内存开销和移动节点的复杂度开销，因此Redis为数据添加上一个属性用于记录最后一次访问的时间，通过随机采样的方式抽取出几个数据，淘汰访问时间最早的那一个。

这种方法无法解决一次性读大量数据但使用频率较小而造成的缓存污染问题，因此引入了LFU算法。



